{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf2.0_learn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imransalam/basic-tf-intro-notebooks/blob/master/tf2_0_learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ZWbGjDXhLTmI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## some tensorflow2.0 stuff....\n",
        "\n",
        "---\n",
        "\n",
        "Please go to runtime type and change the environment to Python3\n",
        "\n",
        "---\n",
        "\n",
        "You can change the hardware accelerator to GPU too\n",
        "\n",
        "---\n",
        "The code written below does not follow \"Good Coding Practices\". This was made for a step by step guide. Hence a lot of things would be repeating.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "7zLKBeamMAdz",
        "colab_type": "code",
        "outputId": "bb4b0764-0c09-4e25-f37d-204ba1e6ba56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.0.0-alpha0\n",
        "import tensorflow as tf\n",
        "print(tf.__version__) # SHOULD BE 2.0.0-alpha0\n",
        "print(tf.executing_eagerly()) # This should be true. Eager Execution skips the old graph-session part."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0-alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/39/f99185d39131b8333afcfe1dcdb0629c2ffc4ecfb0e4c14ca210d620e56c/tensorflow-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (79.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 79.9MB 397kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.0.7)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.2.2)\n",
            "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.0MB 10.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.33.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.1.0)\n",
            "Collecting google-pasta>=0.1.2 (from tensorflow==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/bb/f1bbc131d6294baa6085a222d29abadd012696b73dcbf8cf1bf56b9f082a/google_pasta-0.1.5-py3-none-any.whl (51kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 23.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (3.7.1)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K    100% |████████████████████████████████| 419kB 20.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.16.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.0.9)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-alpha0) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (0.15.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-alpha0) (40.9.0)\n",
            "Installing collected packages: tb-nightly, google-pasta, tf-estimator-nightly, tensorflow\n",
            "  Found existing installation: tensorflow 1.13.1\n",
            "    Uninstalling tensorflow-1.13.1:\n",
            "      Successfully uninstalled tensorflow-1.13.1\n",
            "Successfully installed google-pasta-0.1.5 tb-nightly-1.14.0a20190301 tensorflow-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n",
            "2.0.0-alpha0\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hcUbFHawLG4B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tensors"
      ]
    },
    {
      "metadata": {
        "id": "vpSA6l14ZTln",
        "colab_type": "code",
        "outputId": "41efef07-698b-492c-d0c2-7fff2bf401d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "    Some basic Mathematics Operations Over.... something....\n",
        "'''\n",
        "\n",
        "# No need for graphs :/\n",
        "\n",
        "x = tf.random.normal(shape=(3,3))\n",
        "y = tf.random.normal(shape=(3,3))\n",
        "z = tf.ones(shape=(1))\n",
        "\n",
        "result = z + x * y\n",
        "print(result)\n",
        "\n",
        "# Wait, that's like numpy?!?!?!\n",
        "# You guessed it ;)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.7757539   0.9024863   1.8981946 ]\n",
            " [-0.28960025  1.3480455   1.1079812 ]\n",
            " [-0.46879113  1.0354439   2.1613226 ]], shape=(3, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5ktOYaPYxbJ6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Variables"
      ]
    },
    {
      "metadata": {
        "id": "v24uaImBxhOO",
        "colab_type": "code",
        "outputId": "e14671f9-35de-487c-fad3-25bc97f36109",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "    Some basic Mathematics Operations Over Placeholders and Variables\n",
        "'''\n",
        "\n",
        "# But you lied to us, you said this was just like numpy.\n",
        "# Yes, I lied, But we need to train something, like optimize a variable, CHANGE ITS STATE FROM RANDOM TO SOMETHING USEFUL\n",
        "\n",
        "x = tf.random.normal(shape=(500, 8)) # 500 Examples, 8 Features.\n",
        "\n",
        "w = tf.Variable(tf.random.normal(shape=(8, 3))) # (500x8)*(8x3)=(500,3), We assume that we have 3 classes \n",
        "b = tf.Variable(tf.random.normal(shape=(3,)))\n",
        "\n",
        "y_pred = tf.matmul(x , w) + b\n",
        "\n",
        "print(y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 1.6798445   2.079223    5.089149  ]\n",
            " [-1.3021377   3.3971395   0.1161238 ]\n",
            " [ 2.8522253  -0.15051036  2.1029546 ]\n",
            " ...\n",
            " [-3.3952367  -1.1727492  -3.6189575 ]\n",
            " [ 1.0804975  -1.261142    0.9648686 ]\n",
            " [-1.5507914   3.0282185   1.7486347 ]], shape=(500, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LcDGGivb0D93",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## KICK SOME TRAINING!!!!!!!!!!!!!!!!!!!"
      ]
    },
    {
      "metadata": {
        "id": "We19Ab5L0IsL",
        "colab_type": "code",
        "outputId": "cac6942a-fe44-4410-fc70-aac828387773",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1091
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "    Training Over Boston Housing. Its a simple Linear regression :/\n",
        "'''\n",
        "\n",
        "# LOAD DATASET\n",
        "dataset = tf.keras.datasets.boston_housing\n",
        "(x_train, y_train), (x_val, y_val) = dataset.load_data()\n",
        "\n",
        "# Let's Build a model now!\n",
        "\n",
        "class LinearRegression():\n",
        "    def __init__(self): # Define All your Variables Here. And other configurations\n",
        "        self.lr = 1e-7\n",
        "        self.show_every = 1000\n",
        "        self.epochs = 10000\n",
        "        self.W = tf.Variable(tf.random.normal(shape=(13, 1), dtype=tf.float64), name='W') # (500x8)*(8x3)=(500,3), We assume that we have 3 classes \n",
        "        self.b = tf.Variable(tf.random.normal(shape=(1,), dtype=tf.float64), name='b')\n",
        "    \n",
        "    def predict(self, x): # Use the Configurations and the variables defined here.... this is forward prop\n",
        "        return tf.matmul(x, self.W) + self.b\n",
        "    \n",
        "    def loss(self, predicted_y, desired_y): # The loss function we are going to be using\n",
        "        return tf.reduce_mean(tf.square(predicted_y - desired_y))\n",
        "        \n",
        "    \n",
        "    def fit(self, x, y, val_x, val_y): # Training Loop        \n",
        "        def train_pipe():\n",
        "            with tf.GradientTape() as tape:\n",
        "                loss = self.loss(self.predict(x), y)\n",
        "            dW, db = tape.gradient(loss, [self.W, self.b]) #### WAIT\n",
        "            self.W.assign_sub(self.lr * dW) #### UMM.... WHAT?!?!\n",
        "            self.b.assign_sub(self.lr * db) #### This is gradient Descent... don't worry.\n",
        "            return loss\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            cur_loss = train_pipe()\n",
        "            if epoch % 500 == 0:\n",
        "                val_loss = self.loss(self.predict(val_x), val_y)\n",
        "                print('Epoch Number: ', epoch, ' Loss is: ', cur_loss.numpy() / x.shape[0])\n",
        "                print('Epoch Number: ', epoch, ' Validation Loss is: ', val_loss.numpy() / val_x.shape[0])\n",
        "                print('-'*20)\n",
        "            \n",
        "            \n",
        "            \n",
        "    \n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(x_train, y_train, x_val, y_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n",
            "Epoch Number:  0  Loss is:  1020.8039590949929\n",
            "Epoch Number:  0  Validation Loss is:  3738.635093277587\n",
            "--------------------\n",
            "Epoch Number:  500  Loss is:  2.8412234581556994\n",
            "Epoch Number:  500  Validation Loss is:  8.820767623170394\n",
            "--------------------\n",
            "Epoch Number:  1000  Loss is:  2.240594552556054\n",
            "Epoch Number:  1000  Validation Loss is:  6.9315357930725465\n",
            "--------------------\n",
            "Epoch Number:  1500  Loss is:  1.97180183587482\n",
            "Epoch Number:  1500  Validation Loss is:  6.065736987648328\n",
            "--------------------\n",
            "Epoch Number:  2000  Loss is:  1.7449948304748388\n",
            "Epoch Number:  2000  Validation Loss is:  5.332053684677029\n",
            "--------------------\n",
            "Epoch Number:  2500  Loss is:  1.5518609400363683\n",
            "Epoch Number:  2500  Validation Loss is:  4.710765624502969\n",
            "--------------------\n",
            "Epoch Number:  3000  Loss is:  1.3872659475178022\n",
            "Epoch Number:  3000  Validation Loss is:  4.184923049929645\n",
            "--------------------\n",
            "Epoch Number:  3500  Loss is:  1.2468774340315802\n",
            "Epoch Number:  3500  Validation Loss is:  3.7396953285643657\n",
            "--------------------\n",
            "Epoch Number:  4000  Loss is:  1.1270264276218014\n",
            "Epoch Number:  4000  Validation Loss is:  3.3625186339833273\n",
            "--------------------\n",
            "Epoch Number:  4500  Loss is:  1.0246053726915252\n",
            "Epoch Number:  4500  Validation Loss is:  3.042787205909445\n",
            "--------------------\n",
            "Epoch Number:  5000  Loss is:  0.9369819126183525\n",
            "Epoch Number:  5000  Validation Loss is:  2.7715520063816985\n",
            "--------------------\n",
            "Epoch Number:  5500  Loss is:  0.8619259324369409\n",
            "Epoch Number:  5500  Validation Loss is:  2.5412627468024027\n",
            "--------------------\n",
            "Epoch Number:  6000  Loss is:  0.7975478202649267\n",
            "Epoch Number:  6000  Validation Loss is:  2.3455497246623214\n",
            "--------------------\n",
            "Epoch Number:  6500  Loss is:  0.7422462212761215\n",
            "Epoch Number:  6500  Validation Loss is:  2.1790395640663327\n",
            "--------------------\n",
            "Epoch Number:  7000  Loss is:  0.694663823701141\n",
            "Epoch Number:  7000  Validation Loss is:  2.0371996240851185\n",
            "--------------------\n",
            "Epoch Number:  7500  Loss is:  0.6536499411116711\n",
            "Epoch Number:  7500  Validation Loss is:  1.9162066288341628\n",
            "--------------------\n",
            "Epoch Number:  8000  Loss is:  0.6182288454234903\n",
            "Epoch Number:  8000  Validation Loss is:  1.812835759768418\n",
            "--------------------\n",
            "Epoch Number:  8500  Loss is:  0.587572965960668\n",
            "Epoch Number:  8500  Validation Loss is:  1.7243670327247986\n",
            "--------------------\n",
            "Epoch Number:  9000  Loss is:  0.5609802060644525\n",
            "Epoch Number:  9000  Validation Loss is:  1.648506274442012\n",
            "--------------------\n",
            "Epoch Number:  9500  Loss is:  0.5378547439175476\n",
            "Epoch Number:  9500  Validation Loss is:  1.5833184293903095\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wZUxSTWeBRT2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### THIS IS MORE DIFFICULT THAN TF1.0 ?!?!?!\n",
        "### I know I made it so ;)\n",
        "## Let's see the real magic of TF2.0 with KERAS"
      ]
    },
    {
      "metadata": {
        "id": "9OALhB8kBYbS",
        "colab_type": "code",
        "outputId": "b4bb8452-c03b-44c9-dd9c-1d144fd88154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "    Simple Linear Regression Code with the power of TF with Keras\n",
        "    Training Over Boston Housing. Its a simple Linear regression :/\n",
        "'''\n",
        "\n",
        "# LOAD DATASET\n",
        "dataset = tf.keras.datasets.boston_housing\n",
        "(x_train, y_train), (x_val, y_val) = dataset.load_data()\n",
        "\n",
        "# Let's Build a model now!\n",
        "\n",
        "class LinearRegression(tf.keras.Model): # Subclass from tf.keras.model\n",
        "    def __init__(self): # Define All your Variables Here. And other configurations\n",
        "        super(LinearRegression, self).__init__()\n",
        "        self.dense = tf.keras.layers.Dense(1)\n",
        "    \n",
        "    def call(self, x): # Use the variables defined here.... this is forward prop\n",
        "        return self.dense(x)            \n",
        "    \n",
        "\n",
        "model = LinearRegression()\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "model.fit(x_train, y_train, epochs=10000, verbose=0)\n",
        "model.evaluate(x_val, y_val) / x_val.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102/102 [==============================] - 0s 55us/sample - loss: 23.1735\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.22719119026861664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "gWfprsxBJ75C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### BAM!!!!!!!"
      ]
    },
    {
      "metadata": {
        "id": "TbhbQOYAKAhd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define Custom Loss"
      ]
    },
    {
      "metadata": {
        "id": "UiOObh_mDNcH",
        "colab_type": "code",
        "outputId": "73a90320-da7b-448a-e180-a51225ec107a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "    We are going to do Linear Regression with Huber Loss\n",
        "'''\n",
        "# LOAD DATASET\n",
        "dataset = tf.keras.datasets.boston_housing\n",
        "(x_train, y_train), (x_val, y_val) = dataset.load_data()\n",
        "\n",
        "# Let's Build a model now!\n",
        "\n",
        "def huber_loss(y_true, y_pred, delta):\n",
        "    tf_delta = tf.constant(value=delta, dtype=tf.float32)\n",
        "    residual = tf.reduce_mean(tf.abs(y_pred - y_true))\n",
        "    condition = tf.less(residual, tf_delta)\n",
        "    small_res = 0.5 * tf.square(residual)\n",
        "    large_res = tf_delta * residual - 0.5 * tf.square(tf_delta)\n",
        "    return tf.where(condition, small_res, large_res)\n",
        "\n",
        "def get_loss(delta=1.0):\n",
        "    def huber(y_true, y_pred):\n",
        "        return huber_loss(y_true, y_pred, delta)\n",
        "    return huber\n",
        "\n",
        "class LinearRegression(tf.keras.Model): # Subclass from tf.keras.model\n",
        "    def __init__(self): # Define All your Variables Here. And other configurations\n",
        "        super(LinearRegression, self).__init__()\n",
        "        self.dense = tf.keras.layers.Dense(1)\n",
        "    \n",
        "    def call(self, x): # Use the variables defined here.... this is forward prop\n",
        "        return self.dense(x)            \n",
        "    \n",
        "my_custom_loss = get_loss()\n",
        "model = LinearRegression()\n",
        "model.compile(loss=my_custom_loss, optimizer='adam')\n",
        "model.fit(x_train, y_train, epochs=10000, verbose=0 )\n",
        "model.evaluate(x_val, y_val) / x_val.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102/102 [==============================] - 0s 174us/sample - loss: 2.6805\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.026279310041645406"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "2grFvuDLOT-f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Classification!"
      ]
    },
    {
      "metadata": {
        "id": "5ljwJDUtLibS",
        "colab_type": "code",
        "outputId": "fca0ba11-88b7-47f9-9b5e-e6f57cf7f7ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "    Training Over MNIST\n",
        "'''\n",
        "\n",
        "# LOAD DATASET\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "class LogisticRegression(tf.keras.Model): # Subclass from tf.keras.model\n",
        "    def __init__(self): # Define All your Variables Here. And other configurations\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.dense = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "        self.flatten_layer = tf.keras.layers.Flatten(input_shape=(28, 28))\n",
        "    \n",
        "    def call(self, x): # Use the variables defined here.... this is forward prop\n",
        "        x = self.flatten_layer(x)\n",
        "        x = self.dense(x)\n",
        "        return x\n",
        "        \n",
        "\n",
        "model = LogisticRegression()\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'],)\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "model.evaluate(x_test, y_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 3s 49us/sample - loss: 1.6382 - accuracy: 0.5839\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 1.0353 - accuracy: 0.7996\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.8233 - accuracy: 0.8286\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.7159 - accuracy: 0.8422\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.6500 - accuracy: 0.8509\n",
            "10000/10000 [==============================] - 0s 36us/sample - loss: 0.5995 - accuracy: 0.8636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5994680000305176, 0.8636]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "toAh806XSR5Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## One Hidden Layer"
      ]
    },
    {
      "metadata": {
        "id": "CRy3qBijOjkT",
        "colab_type": "code",
        "outputId": "2cfb5ee5-4c3b-4f01-85ec-6526dee14353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "    Training Over MNIST\n",
        "'''\n",
        "\n",
        "# LOAD DATASET\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "class OneLayeredNNClassification(tf.keras.Model): # Subclass from tf.keras.model\n",
        "    def __init__(self): # Define All your Variables Here. And other configurations\n",
        "        super(OneLayeredNNClassification, self).__init__()\n",
        "        self.dense_final = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "        self.dense = tf.keras.layers.Dense(512, activation=tf.nn.relu)\n",
        "        self.flatten_layer = tf.keras.layers.Flatten(input_shape=(28, 28))\n",
        "    \n",
        "    def call(self, x): # Use the variables defined here.... this is forward prop\n",
        "        x = self.flatten_layer(x)\n",
        "        x = self.dense(x)\n",
        "        x = self.dense_final(x)\n",
        "        return x\n",
        "        \n",
        "\n",
        "model = OneLayeredNNClassification()\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'],)\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "model.evaluate(x_test, y_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 1.5514 - accuracy: 0.6519\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 8s 141us/sample - loss: 0.8346 - accuracy: 0.8310\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.6205 - accuracy: 0.8582\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 8s 141us/sample - loss: 0.5249 - accuracy: 0.8716\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.4702 - accuracy: 0.8803\n",
            "10000/10000 [==============================] - 1s 78us/sample - loss: 0.4303 - accuracy: 0.8901\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4302520763158798, 0.8901]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "XAxA14CfTGSJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Stack More Layers"
      ]
    },
    {
      "metadata": {
        "id": "i7It1g7GS2qF",
        "colab_type": "code",
        "outputId": "9b64dbe2-e515-471b-8e49-4e8673b11439",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "    Training Over MNIST\n",
        "'''\n",
        "\n",
        "# LOAD DATASET\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "class NNClassification(tf.keras.Model): # Subclass from tf.keras.model\n",
        "    def __init__(self): # Define All your Variables Here. And other configurations\n",
        "        super(NNClassification, self).__init__()\n",
        "        self.dense_final = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "        self.dense1 = tf.keras.layers.Dense(256, activation=tf.nn.relu)\n",
        "        self.dense2 = tf.keras.layers.Dense(256, activation=tf.nn.relu)\n",
        "        self.dense3 = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n",
        "        self.flatten_layer = tf.keras.layers.Flatten(input_shape=(28, 28))\n",
        "    \n",
        "    def call(self, x): # Use the variables defined here.... this is forward prop\n",
        "        x = self.flatten_layer(x)\n",
        "        x = self.dense1(x)\n",
        "        x = self.dense2(x)\n",
        "        x = self.dense3(x)\n",
        "        x = self.dense_final(x)\n",
        "        return x\n",
        "        \n",
        "\n",
        "model = NNClassification()\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'],)\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "model.evaluate(x_test, y_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 125us/sample - loss: 1.9297 - accuracy: 0.4965\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.9364 - accuracy: 0.7970\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 0.5654 - accuracy: 0.8556\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.4462 - accuracy: 0.8808\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 9s 144us/sample - loss: 0.3877 - accuracy: 0.8936\n",
            "10000/10000 [==============================] - 1s 76us/sample - loss: 0.3532 - accuracy: 0.9000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3532075037121773, 0.9]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "xmki-nbxT9u3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ConvNets - Saving a Model"
      ]
    },
    {
      "metadata": {
        "id": "eaQ9djkaTr8T",
        "colab_type": "code",
        "outputId": "cc801ec7-e22d-46bd-8111-8fcb4cec2e3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "    Training Over MNIST\n",
        "'''\n",
        "\n",
        "# LOAD DATASET\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "class ConvNetClassification(tf.keras.Model): # Subclass from tf.keras.model\n",
        "    def __init__(self): # Define All your Variables Here. And other configurations\n",
        "        super(ConvNetClassification, self).__init__()\n",
        "        self.conv2d_1 = tf.keras.layers.Conv2D(32, (5,5), padding='same', activation='relu')\n",
        "        self.max2d_1 = tf.keras.layers.MaxPool2D((3,3), padding='valid', strides=(2,2))\n",
        "        self.conv2d_2 = tf.keras.layers.Conv2D(64, (5,5), padding='same', activation='relu')\n",
        "        self.max2d_2 = tf.keras.layers.MaxPool2D((3,3), padding='valid', strides=(2,2))\n",
        "        \n",
        "        self.flatten_layer = tf.keras.layers.Flatten()\n",
        "        self.dense1 = tf.keras.layers.Dense(1000, activation=tf.nn.relu)\n",
        "        self.dense2 = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n",
        "        self.dense_final = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "    \n",
        "    def call(self, x): # Use the variables defined here.... this is forward prop\n",
        "        x = self.conv2d_1(x)\n",
        "        x = self.max2d_1(x)\n",
        "        x = self.conv2d_2(x)\n",
        "        x = self.max2d_2(x)\n",
        "        x = self.flatten_layer(x)\n",
        "        x = self.dense1(x)\n",
        "        x = self.dense2(x)\n",
        "        x = self.dense_final(x)\n",
        "        return x\n",
        "        \n",
        "\n",
        "model = ConvNetClassification()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=1, batch_size=4)\n",
        "model.evaluate(x_test, y_test)\n",
        "\n",
        "\n",
        "model.save_weights('My-ConvNet-Model.h5')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 648s 11ms/sample - loss: 0.1162 - accuracy: 0.9660\n",
            "10000/10000 [==============================] - 8s 819us/sample - loss: 0.0580 - accuracy: 0.9828\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-f232b82a81f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'My-ConvNet-Model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1305\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       raise NotImplementedError(\n\u001b[0;32m-> 1307\u001b[0;31m           \u001b[0;34m'The `save` method requires the model to be a Functional model or a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1308\u001b[0m           \u001b[0;34m'Sequential model. It does not work for subclassed models, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m           \u001b[0;34m'because such models are defined via the body of a Python method, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: The `save` method requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider using `save_weights`, in order to save the weights of the model."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "96GKq2eNbxjV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Model"
      ]
    },
    {
      "metadata": {
        "id": "H1yHnMaZXaDr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ConvNetClassification(tf.keras.Model): # Subclass from tf.keras.model\n",
        "    def __init__(self): # Define All your Variables Here. And other configurations\n",
        "        super(ConvNetClassification, self).__init__()\n",
        "        self.conv2d_1 = tf.keras.layers.Conv2D(32, (5,5), padding='same', activation='relu')\n",
        "        self.max2d_1 = tf.keras.layers.MaxPool2D((3,3), padding='valid', strides=(2,2))\n",
        "        self.conv2d_2 = tf.keras.layers.Conv2D(64, (5,5), padding='same', activation='relu')\n",
        "        self.max2d_2 = tf.keras.layers.MaxPool2D((3,3), padding='valid', strides=(2,2))\n",
        "        \n",
        "        self.flatten_layer = tf.keras.layers.Flatten()\n",
        "        self.dense1 = tf.keras.layers.Dense(1000, activation=tf.nn.relu)\n",
        "        self.dense2 = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n",
        "        self.dense_final = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "    \n",
        "    def call(self, x): # Use the variables defined here.... this is forward prop\n",
        "        x = self.conv2d_1(x)\n",
        "        x = self.max2d_1(x)\n",
        "        x = self.conv2d_2(x)\n",
        "        x = self.max2d_2(x)\n",
        "        x = self.flatten_layer(x)\n",
        "        x = self.dense1(x)\n",
        "        x = self.dense2(x)\n",
        "        x = self.dense_final(x)\n",
        "        return x\n",
        "    \n",
        "model = ConvNetClassification()\n",
        "model.load_weights('My-ConvNet-Model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rjNh6n18a-z6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}